# DRAFT Large Language Models (LLM) Usage Policy for Health Data Insight (HDI)

1. **Purpose and Scope**

This policy provides guidelines for using large language models (LLMs) such as OpenAI's ChatGPT or Anthropic's Claude within HDI.
Given our focus on healthcare, this policy also emphasizes the critical importance of patient privacy, data security, and regulatory compliance. It applies to all employees, contractors, and partners who utilize LLMs as part of their role.

2. **Responsible Use**

We should use LLMs to enhance our services, improve patient outcomes, and contribute to research while upholding the highest ethical standards.
Any inappropriate or unethical use of LLMs is strictly prohibited, including producing harmful or deceptive content.

3. **Data Privacy & Compliance with Health Regulations**

<!--alex ignore special-->
All use of LLMs must adhere to strict data privacy standards, particularly those relating to "special categories of personal data" under GDPR.
Under no circumstances should patient-specific data be used without explicit consent and appropriate anonymization/de-identification measures.

4. **Transparency**

Any interaction with external parties, particularly patients and healthcare providers, should indicate the involvement of an LLM.
You must obtain consent for data processing if personal or health data is involved, and you should communicate the potential impacts of this interaction.

5. **Bias and Fairness**

It is crucial to remember that LLMs can reflect societal biases in their training data, which can be particularly impactful in a healthcare setting.
All users must make concerted efforts to recognize and mitigate these biases.
You should promptly report any suspected bias or discriminatory output for review.

6. **Training and Compliance**

All users must receive training on LLMs' operation, capabilities, and limitations, focusing on potential ethical, legal, and privacy implications in a healthcare context.
Adherence to this policy is mandatory, and non-compliance may lead to disciplinary action, up to and including termination of employment.

7. **Oversight and Accountability**

Our AI Ethics Committee will oversee the use of LLMs within the company, ensuring policy compliance and performing regular audits.
You should report any concerns about LLM use directly to this committee.

8. **Security**

Given the sensitive nature of our work, robust cybersecurity measures are crucial when using LLMs.
These measures include secure handling of credentials, using secure and encrypted networks, and promptly reporting any security incidents or potential vulnerabilities.

9. **Updating Policy**

Due to the rapid evolution of AI technologies and healthcare regulations, we will update this policy periodically.
We will communicate all updates company-wide and provide additional training as necessary.

By using LLMs within your role at HDI, you agree to abide by these guidelines, recognizing that responsible AI use is vital for maintaining the trust of our patients, partners, and regulatory bodies and upholding our company's commitment to ethical healthcare practices.
